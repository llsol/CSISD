{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d9db959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/lluis/master-thesis/CSISD'),\n",
       " PosixPath('/home/lluis/master-thesis/CSISD/data/interim'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    _HAS_SNS = True\n",
    "except Exception:\n",
    "    _HAS_SNS = False\n",
    "\n",
    "\n",
    "def find_project_root(start=None):\n",
    "    if start is None:\n",
    "        start = Path.cwd().resolve()\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data\").exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_INTERIM = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "PROJECT_ROOT, DATA_INTERIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a0d0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " [PosixPath('/home/lluis/master-thesis/CSISD/data/interim/srs_v1_bdn_sav/features/srs_v1_bdn_sav_svara_features.parquet'),\n",
       "  PosixPath('/home/lluis/master-thesis/CSISD/data/interim/srs_v1_drn_sav/features/srs_v1_drn_sav_svara_features.parquet'),\n",
       "  PosixPath('/home/lluis/master-thesis/CSISD/data/interim/srs_v1_psn_sav/features/srs_v1_psn_sav_svara_features.parquet'),\n",
       "  PosixPath('/home/lluis/master-thesis/CSISD/data/interim/srs_v1_rkm_sav/features/srs_v1_rkm_sav_svara_features.parquet'),\n",
       "  PosixPath('/home/lluis/master-thesis/CSISD/data/interim/srs_v1_svd_sav/features/srs_v1_svd_sav_svara_features.parquet')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "FEATURE_GLOB = \"*/features/*svara_features.parquet\"\n",
    "\n",
    "ID_COLS = {\n",
    "    \"recording_id\", \"piece_id\", \"file\",\n",
    "    \"svara_id\",\n",
    "    \"svara_start_sec\", \"svara_end_sec\", \"svara_duration_sec\", \"svara_n_rows\",\n",
    "}\n",
    "\n",
    "LABEL_COLS_CANDIDATES = {\n",
    "    \"svara_label\", \"prev_svara\", \"next_svara\",\n",
    "    \"section_label\",\n",
    "    \"svara_lower\", \"svara_upper\",\n",
    "}\n",
    "\n",
    "feature_paths = sorted(DATA_INTERIM.glob(FEATURE_GLOB))\n",
    "len(feature_paths), feature_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f93840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current working directory\n",
    "Path.cwd()\n",
    "#go to project root\n",
    "#Path.cwd().parent.parent\n",
    "project_root = find_project_root()\n",
    "import sys\n",
    "sys.path.append(str(project_root))\n",
    "from src.io.pitch_io import load_pitch_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b375c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARQUET has svara_label? False\n",
      "LOADER has svara_label? False\n"
     ]
    }
   ],
   "source": [
    "from src.io.pitch_io import load_pitch_file\n",
    "\n",
    "for preprocessed_path in feature_paths[:1]:\n",
    "    df = pl.read_parquet(preprocessed_path)\n",
    "    print(\"PARQUET has svara_label?\", \"svara_label\" in df.columns)\n",
    "\n",
    "    df2 = load_pitch_file(preprocessed_path)\n",
    "    print(\"LOADER has svara_label?\", \"svara_label\" in df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ef17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2760, 21),\n",
       " ['recording_id',\n",
       "  'svara_id',\n",
       "  'svara',\n",
       "  'svara_start_sec',\n",
       "  'svara_end_sec',\n",
       "  'svara_duration_sec',\n",
       "  'svara_n_rows',\n",
       "  'duration_sec',\n",
       "  'pitch_mean',\n",
       "  'pitch_median',\n",
       "  'pitch_std',\n",
       "  'pitch_range',\n",
       "  'slope_global',\n",
       "  'd1_mean',\n",
       "  'd1_std',\n",
       "  'd1_abs_mean',\n",
       "  'd1_abs_std',\n",
       "  'd2_mean',\n",
       "  'd2_std',\n",
       "  'd2_abs_mean'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega i concatena (scan_parquet)\n",
    "\n",
    "if len(feature_paths) == 0:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No he trobat parquets amb el patró {FEATURE_GLOB} dins {DATA_INTERIM}. \"\n",
    "        \"Revisa el glob o el directori.\"\n",
    "    )\n",
    "\n",
    "scans = [pl.scan_parquet(p) for p in feature_paths]\n",
    "df = pl.concat(scans, how=\"vertical_relaxed\").collect()\n",
    "df.shape, df.columns[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c1763f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>recording_id</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;srs_v1_bdn_sav&quot;</td></tr><tr><td>&quot;srs_v1_bdn_sav&quot;</td></tr><tr><td>&quot;srs_v1_bdn_sav&quot;</td></tr><tr><td>&quot;srs_v1_bdn_sav&quot;</td></tr><tr><td>&quot;srs_v1_bdn_sav&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌────────────────┐\n",
       "│ recording_id   │\n",
       "│ ---            │\n",
       "│ str            │\n",
       "╞════════════════╡\n",
       "│ srs_v1_bdn_sav │\n",
       "│ srs_v1_bdn_sav │\n",
       "│ srs_v1_bdn_sav │\n",
       "│ srs_v1_bdn_sav │\n",
       "│ srs_v1_bdn_sav │\n",
       "└────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assegura recording_id (si falta, el derivem del path)\n",
    "\n",
    "if \"recording_id\" not in df.columns:\n",
    "    rec_ids = []\n",
    "    for p in feature_paths:\n",
    "        # data/interim/<recording_id>/features/...\n",
    "        parts = p.parts\n",
    "        if \"interim\" in parts:\n",
    "            rid = parts[parts.index(\"interim\") + 1]\n",
    "        else:\n",
    "            rid = p.parent.parent.name\n",
    "        rec_ids.append(rid)\n",
    "\n",
    "    dfs = []\n",
    "    for p, rid in zip(feature_paths, rec_ids):\n",
    "        d = pl.read_parquet(p)\n",
    "        d = d.with_columns(pl.lit(rid).alias(\"recording_id\"))\n",
    "        dfs.append(d)\n",
    "\n",
    "    df = pl.concat(dfs, how=\"vertical_relaxed\")\n",
    "\n",
    "df.select([\"recording_id\"]).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20141fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_rows': 2760,\n",
       " 'n_cols': 21,\n",
       " 'n_recordings': 5,\n",
       " 'n_id_cols_present': 6,\n",
       " 'n_label_cols_present': 0,\n",
       " 'n_numeric_features': 14}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifica features automàticament\n",
    "\n",
    "present_id_cols = [c for c in ID_COLS if c in df.columns]\n",
    "present_label_cols = [c for c in LABEL_COLS_CANDIDATES if c in df.columns]\n",
    "\n",
    "numeric_cols = [c for c, dt in zip(df.columns, df.dtypes) if dt.is_numeric()]\n",
    "numeric_features = [c for c in numeric_cols if c not in set(present_id_cols) | set(present_label_cols)]\n",
    "\n",
    "summary = {\n",
    "    \"n_rows\": df.height,\n",
    "    \"n_cols\": df.width,\n",
    "    \"n_recordings\": df.select(pl.col(\"recording_id\").n_unique()).item(),\n",
    "    \"n_id_cols_present\": len(present_id_cols),\n",
    "    \"n_label_cols_present\": len(present_label_cols),\n",
    "    \"n_numeric_features\": len(numeric_features),\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe36e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>recording_id</th><th>n_segments</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;srs_v1_bdn_sav&quot;</td><td>581</td></tr><tr><td>&quot;srs_v1_drn_sav&quot;</td><td>578</td></tr><tr><td>&quot;srs_v1_svd_sav&quot;</td><td>570</td></tr><tr><td>&quot;srs_v1_psn_sav&quot;</td><td>530</td></tr><tr><td>&quot;srs_v1_rkm_sav&quot;</td><td>501</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────────┬────────────┐\n",
       "│ recording_id   ┆ n_segments │\n",
       "│ ---            ┆ ---        │\n",
       "│ str            ┆ u32        │\n",
       "╞════════════════╪════════════╡\n",
       "│ srs_v1_bdn_sav ┆ 581        │\n",
       "│ srs_v1_drn_sav ┆ 578        │\n",
       "│ srs_v1_svd_sav ┆ 570        │\n",
       "│ srs_v1_psn_sav ┆ 530        │\n",
       "│ srs_v1_rkm_sav ┆ 501        │\n",
       "└────────────────┴────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recompte per recording\n",
    "\n",
    "counts_by_rec = (\n",
    "    df.group_by(\"recording_id\")\n",
    "      .agg(pl.len().alias(\"n_segments\"))\n",
    "      .sort(\"n_segments\", descending=True)\n",
    ")\n",
    "counts_by_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2255524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>svara</th><th>n_segments</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;D&quot;</td><td>616</td></tr><tr><td>&quot;R&quot;</td><td>471</td></tr><tr><td>&quot;P&quot;</td><td>470</td></tr><tr><td>&quot;S&quot;</td><td>401</td></tr><tr><td>&quot;M&quot;</td><td>345</td></tr><tr><td>&quot;N&quot;</td><td>247</td></tr><tr><td>&quot;G&quot;</td><td>210</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌───────┬────────────┐\n",
       "│ svara ┆ n_segments │\n",
       "│ ---   ┆ ---        │\n",
       "│ str   ┆ u32        │\n",
       "╞═══════╪════════════╡\n",
       "│ D     ┆ 616        │\n",
       "│ R     ┆ 471        │\n",
       "│ P     ┆ 470        │\n",
       "│ S     ┆ 401        │\n",
       "│ M     ┆ 345        │\n",
       "│ N     ┆ 247        │\n",
       "│ G     ┆ 210        │\n",
       "└───────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recompte per svara (si existeix)\n",
    "\n",
    "if \"svara\" in df.columns:\n",
    "    counts_by_svara_label = (\n",
    "        df.group_by(\"svara\")\n",
    "          .agg(pl.len().alias(\"n_segments\"))\n",
    "          .sort(\"n_segments\", descending=True)\n",
    "    )\n",
    "    display(counts_by_svara_label)\n",
    "else:\n",
    "    print(\"No hi ha columna 'svara' al parquet (encara).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab86408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness (NaNs + nulls) per feature\n",
    "\n",
    "if len(numeric_features) == 0:\n",
    "    print(\"No hi ha features numèriques detectades.\")\n",
    "else:\n",
    "    miss = df.select([\n",
    "        (pl.col(c).is_null().sum() + pl.col(c).is_nan().sum()).alias(c)\n",
    "        for c in numeric_features\n",
    "    ]).to_dicts()[0]\n",
    "\n",
    "    miss_df = (\n",
    "        pl.DataFrame({\n",
    "            \"feature\": list(miss.keys()),\n",
    "            \"missing_count\": list(miss.values()),\n",
    "        })\n",
    "        .with_columns((pl.col(\"missing_count\") / df.height).alias(\"missing_frac\"))\n",
    "        .sort(\"missing_frac\", descending=True)\n",
    "    )\n",
    "\n",
    "    display(miss_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features constants (variança 0)\n",
    "\n",
    "if len(numeric_features) > 0:\n",
    "    var_map = df.select([pl.col(c).var().alias(c) for c in numeric_features]).to_dicts()[0]\n",
    "\n",
    "    var_df = (\n",
    "        pl.DataFrame({\"feature\": list(var_map.keys()), \"variance\": list(var_map.values())})\n",
    "        .sort(\"variance\")\n",
    "    )\n",
    "\n",
    "    display(var_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027034b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicats (recording_id, svara_id)\n",
    "\n",
    "if \"recording_id\" in df.columns and \"svara_id\" in df.columns:\n",
    "    dup = (\n",
    "        df.group_by([\"recording_id\", \"svara_id\"])\n",
    "          .agg(pl.len().alias(\"n\"))\n",
    "          .filter(pl.col(\"n\") > 1)\n",
    "          .sort(\"n\", descending=True)\n",
    "    )\n",
    "    if dup.height == 0:\n",
    "        print(\"OK: no hi ha duplicats (recording_id, svara_id).\")\n",
    "    else:\n",
    "        print(\"ATENCIÓ: hi ha duplicats!\")\n",
    "        dup.head(20)\n",
    "else:\n",
    "    print(\"No puc comprovar duplicats: falta recording_id o svara_id.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribució de durades de segments\n",
    "\n",
    "if \"svara_duration_sec\" in df.columns:\n",
    "    dur = df[\"svara_duration_sec\"].to_numpy()\n",
    "    dur = dur[np.isfinite(dur)]\n",
    "\n",
    "    print({\n",
    "        \"n_finite\": int(len(dur)),\n",
    "        \"min\": float(np.min(dur)) if len(dur) else np.nan,\n",
    "        \"p05\": float(np.quantile(dur, 0.05)) if len(dur) else np.nan,\n",
    "        \"median\": float(np.median(dur)) if len(dur) else np.nan,\n",
    "        \"p95\": float(np.quantile(dur, 0.95)) if len(dur) else np.nan,\n",
    "        \"max\": float(np.max(dur)) if len(dur) else np.nan,\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    if _HAS_SNS:\n",
    "        sns.histplot(dur, bins=50)\n",
    "    else:\n",
    "        plt.hist(dur, bins=50)\n",
    "    plt.title(\"Segment duration distribution\")\n",
    "    plt.xlabel(\"svara_duration_sec\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hi ha columna svara_duration_sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de durades (tweakable)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- PARAMETRES (tweak) ---\n",
    "DUR_COL = \"svara_duration_sec\"\n",
    "BINS = 60                  # int o \"fd\" / \"sturges\" / \"sqrt\" / \"auto\"\n",
    "RANGE = None               # p.ex. (0, 1.0) per zoom; None = sense\n",
    "LOG_Y = False              # True si vols veure cues llargues\n",
    "SHOW_RUG = False           # punts a sota (matplotlib)\n",
    "DROP_ZERO = True           # treu durades 0 si hi ha errors\n",
    "CLIP_QUANTILES = None      # p.ex. (0.01, 0.99) per treure outliers visuals\n",
    "\n",
    "# --- DATA ---\n",
    "if DUR_COL not in df.columns:\n",
    "    raise ValueError(f\"No hi ha columna {DUR_COL}\")\n",
    "\n",
    "dur = df[DUR_COL].to_numpy()\n",
    "dur = dur[np.isfinite(dur)]\n",
    "\n",
    "if DROP_ZERO:\n",
    "    dur = dur[dur > 0]\n",
    "\n",
    "if CLIP_QUANTILES is not None and len(dur) > 0:\n",
    "    qlo, qhi = CLIP_QUANTILES\n",
    "    lo = np.quantile(dur, qlo)\n",
    "    hi = np.quantile(dur, qhi)\n",
    "    dur = dur[(dur >= lo) & (dur <= hi)]\n",
    "\n",
    "print({\n",
    "    \"n\": int(len(dur)),\n",
    "    \"min\": float(np.min(dur)) if len(dur) else np.nan,\n",
    "    \"p05\": float(np.quantile(dur, 0.05)) if len(dur) else np.nan,\n",
    "    \"median\": float(np.median(dur)) if len(dur) else np.nan,\n",
    "    \"p95\": float(np.quantile(dur, 0.95)) if len(dur) else np.nan,\n",
    "    \"max\": float(np.max(dur)) if len(dur) else np.nan,\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.hist(dur, bins=BINS, range=RANGE)\n",
    "plt.title(\"Segment duration distribution\")\n",
    "plt.xlabel(DUR_COL)\n",
    "plt.ylabel(\"count\")\n",
    "if LOG_Y:\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "if SHOW_RUG and len(dur) > 0:\n",
    "    y0 = plt.ylim()[0]\n",
    "    plt.plot(dur, np.full_like(dur, y0), \"|\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fdf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma per peça (recording_id) amb paràmetres i opció de filtre per nombre mínim de segments\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DUR_COL = \"svara_duration_sec\"\n",
    "GROUP_COL = \"recording_id\"\n",
    "\n",
    "# --- PARAMETRES (tweak) ---\n",
    "BINS = 50\n",
    "RANGE = None               # p.ex. (0, 1.0)\n",
    "LOG_Y = False\n",
    "MIN_SEGMENTS = 20          # no plotis peces massa petites\n",
    "MAX_PLOTS = 12             # limita per no fer 50 figures\n",
    "ORDER_BY = \"n\"             # \"n\" o \"median\"\n",
    "\n",
    "if DUR_COL not in df.columns:\n",
    "    raise ValueError(f\"No hi ha columna {DUR_COL}\")\n",
    "if GROUP_COL not in df.columns:\n",
    "    raise ValueError(f\"No hi ha columna {GROUP_COL}\")\n",
    "\n",
    "# resume per peça\n",
    "summary = (\n",
    "    df.select([GROUP_COL, DUR_COL])\n",
    "      .filter(pl.col(DUR_COL).is_not_null())\n",
    "      .group_by(GROUP_COL)\n",
    "      .agg([\n",
    "          pl.len().alias(\"n\"),\n",
    "          pl.col(DUR_COL).median().alias(\"median\"),\n",
    "      ])\n",
    ")\n",
    "\n",
    "if ORDER_BY == \"median\":\n",
    "    summary = summary.sort(\"median\", descending=True)\n",
    "else:\n",
    "    summary = summary.sort(\"n\", descending=True)\n",
    "\n",
    "groups = summary.filter(pl.col(\"n\") >= MIN_SEGMENTS).get_column(GROUP_COL).to_list()\n",
    "groups = groups[:MAX_PLOTS]\n",
    "\n",
    "print(f\"Peces plotejades: {len(groups)} (MIN_SEGMENTS={MIN_SEGMENTS}, MAX_PLOTS={MAX_PLOTS})\")\n",
    "\n",
    "for rid in groups:\n",
    "    dur = (\n",
    "        df.filter(pl.col(GROUP_COL) == rid)\n",
    "          .select(DUR_COL)\n",
    "          .to_series()\n",
    "          .to_numpy()\n",
    "    )\n",
    "    dur = dur[np.isfinite(dur)]\n",
    "    dur = dur[dur > 0]\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    plt.hist(dur, bins=BINS, range=RANGE)\n",
    "    plt.title(f\"Duration histogram — {rid} (n={len(dur)})\")\n",
    "    plt.xlabel(DUR_COL)\n",
    "    plt.ylabel(\"count\")\n",
    "    if LOG_Y:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALT DE CEL·LA\n",
    "# Overlay per comparar peces (normalitzat a densitat)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DUR_COL = \"svara_duration_sec\"\n",
    "GROUP_COL = \"recording_id\"\n",
    "\n",
    "# --- PARAMETRES (tweak) ---\n",
    "BINS = 60\n",
    "RANGE = (0, 1.5)          # habitualment ajuda posar un rang fix per comparar\n",
    "TOP_K = 6                 # compara les TOP K per n\n",
    "DENSITY = True            # normalitza a densitat (compara formes)\n",
    "ALPHA = 0.4\n",
    "\n",
    "summary = (\n",
    "    df.select([GROUP_COL, DUR_COL])\n",
    "      .filter(pl.col(DUR_COL).is_not_null())\n",
    "      .group_by(GROUP_COL)\n",
    "      .agg(pl.len().alias(\"n\"))\n",
    "      .sort(\"n\", descending=True)\n",
    ")\n",
    "\n",
    "top = summary.get_column(GROUP_COL).to_list()[:TOP_K]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for rid in top:\n",
    "    dur = (\n",
    "        df.filter(pl.col(GROUP_COL) == rid)\n",
    "          .select(DUR_COL)\n",
    "          .to_series()\n",
    "          .to_numpy()\n",
    "    )\n",
    "    dur = dur[np.isfinite(dur)]\n",
    "    dur = dur[dur > 0]\n",
    "    plt.hist(dur, bins=BINS, range=RANGE, density=DENSITY, alpha=ALPHA, label=rid)\n",
    "\n",
    "plt.title(\"Duration distribution by recording (overlay)\")\n",
    "plt.xlabel(DUR_COL)\n",
    "plt.ylabel(\"density\" if DENSITY else \"count\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look: top missingness and top variance\n",
    "\n",
    "if len(numeric_features) > 0:\n",
    "    print(\"--- Missingness (top 15) ---\")\n",
    "    if \"miss_df\" in globals():\n",
    "        print(miss_df.head(15))\n",
    "\n",
    "    print(\"\\n--- Variance (top 15) ---\")\n",
    "    if \"var_df\" in globals():\n",
    "        print(var_df.sort(\"variance\", descending=True).head(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
